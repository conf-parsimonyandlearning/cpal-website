---
name: "Yihua Zhang"
role: "Researcher"
affiliation: ""
website: ""
photo: "image3.png"
talk: "Authenticity and Resilience: New Frontiers in Machine Unlearning for Large Language Models"
abstract: "Machine unlearning has emerged as a powerful approach for selectively removing harmful or undesirable knowledge from large language models (LLMs) while preserving their general capabilities. However, recent findings reveal significant pitfalls in existing unlearning methods, including 'fake unlearning'—where knowledge is merely hidden rather than truly removed. Such incomplete removal can render models highly vulnerable to malicious attacks or unintentional downstream fine-tunings. In this talk, we will explore how authenticity—the genuine erasure of targeted knowledge—and resilience—robustness to relearning and finetuning—can jointly serve as guiding principles for more effective machine unlearning. Drawing on both theoretical insights and empirical findings, we discuss novel strategies such as second-order optimization, weight attribution analysis, invariance-regularized training, and sharpness-aware unlearning. We show how these approaches not only address 'fake unlearning' but also provide even more benefits. By mapping out these new frontiers, our work contributes practical insights and foundational ideas to help researchers and practitioners develop robust, efficient, and truly trustworthy unlearning solutions for the next generation of large language models."
session: "1"
order: "3"
---
