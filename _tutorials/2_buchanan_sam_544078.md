---
name: Sam Buchanan
role: Research Assistant Professor
affiliation: TTIC
website: https://sdbuchanan.com
photo: sdb.jpg
order: 2
track: 1
tutorial: "White-Box Transformers via Sparse Rate Reduction"
abstract: "We demonstrate how combining sparse coding and rate reduction yields sparse linear discriminative representations using an objective named “sparse rate reduction”. We develop CRATE, a deep network architecture, by unrolling the optimization of this objective and parameterizing feature distribution in each layer. CRATE’s operators are mathematically interpretable, with each layer representing an optimization step, making the network a transparent “white box”. Although CRATE’s design significantly differs from ReduNet, both aim for a similar goal, showcasing the versatility of the unrolled optimization approach. Remarkably, CRATE closely resembles the transformer architecture, suggesting that the interpretability gains from such networks might also improve our understanding of current, practical deep architectures."
---
