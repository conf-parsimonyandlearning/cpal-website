<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><title>Keynote Speakers | Conference on Parsimony and Learning (CPAL)</title><meta name="generator" content="Jekyll v3.9.0" /><meta property="og:title" content="Keynote Speakers" /><meta property="og:locale" content="en_US" /><meta name="description" content="Conference on Parsimony and Learning (CPAL) - Addressing the low-dimensional structures in high-dimensional data that prevail in machine learning, signal processing, optimization, and beyond." /><meta property="og:description" content="Conference on Parsimony and Learning (CPAL) - Addressing the low-dimensional structures in high-dimensional data that prevail in machine learning, signal processing, optimization, and beyond." /><link rel="canonical" href="http://localhost:4000/speakers/" /><meta property="og:url" content="http://localhost:4000/speakers/" /><meta property="og:site_name" content="Conference on Parsimony and Learning (CPAL)" /><meta property="og:image" content="http://localhost:4000/assets/images/card.png" /><meta property="og:type" content="website" /><meta name="twitter:card" content="summary_large_image" /><meta property="twitter:image" content="http://localhost:4000/assets/images/card.png" /><meta property="twitter:title" content="Keynote Speakers" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"Conference on Parsimony and Learning (CPAL) - Addressing the low-dimensional structures in high-dimensional data that prevail in machine learning, signal processing, optimization, and beyond.","headline":"Keynote Speakers","image":"http://localhost:4000/assets/images/card.png","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/images/logo.svg"}},"url":"http://localhost:4000/speakers/"}</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous"> <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script> <script defer src="/assets/js/mathtex-script-type.js"> </script> <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body, { globalGroup: true, trust: true, strict: false, throwOnError: false, });"></script><style> .katex { font-size: 1em; }</style><body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"><title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"><title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"><title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"><title id="svg-external-link-title">(external link)</title><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"><title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"><title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-copy" viewBox="0 0 16 16"><title>Copy</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/><path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"><title>Copied</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"><path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg><div class="side-bar"><div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"><div class="site-logo" role="img" aria-label="Conference on Parsimony and Learning (CPAL)"></div></a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </a></div><nav aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item"> <a href="/" class="nav-list-link">Home</a><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Register & Attend category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <button class="nav-list-link-expander btn-reset" aria-label="toggle items in Register & Attend category" aria-pressed="false"> Register & Attend </button><ul class="nav-list"><li class="nav-list-item "> <a href="/venue/" class="nav-list-link">CPAL Logistics and Venue</a><li class="nav-list-item "> <a href="/registration/" class="nav-list-link">Registration</a><li class="nav-list-item "> <a href="/visa/" class="nav-list-link">Travel: Visa Information</a><li class="nav-list-item "> <a href="/hotels/" class="nav-list-link">Travel: Hotels</a></ul><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Accepted Papers category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <button class="nav-list-link-expander btn-reset" aria-label="toggle items in Accepted Papers category" aria-pressed="false"> Accepted Papers </button><ul class="nav-list"><li class="nav-list-item "> <a href="/proceedings_track/" class="nav-list-link">Proceedings Track</a><li class="nav-list-item "> <a href="/spotlight_track/" class="nav-list-link">Spotlight Track</a></ul><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Conference Program category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <button class="nav-list-link-expander btn-reset" aria-label="toggle items in Conference Program category" aria-pressed="false"> Conference Program </button><ul class="nav-list"><li class="nav-list-item "> <a href="/program_schedule/" class="nav-list-link">Program at a Glance</a><li class="nav-list-item "> <a href="/orals/" class="nav-list-link">Oral Presentations</a><li class="nav-list-item "> <a href="/posters/" class="nav-list-link">Poster Presentations</a><li class="nav-list-item "> <a href="/rising_stars_presentations/" class="nav-list-link">Rising Stars Presentations</a></ul><li class="nav-list-item active"> <a href="/speakers/" class="nav-list-link active">Keynote Speakers</a><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Tutorials category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <button class="nav-list-link-expander btn-reset" aria-label="toggle items in Tutorials category" aria-pressed="false"> Tutorials </button><ul class="nav-list"><li class="nav-list-item "> <a href="/tutorial_info/" class="nav-list-link">List of Tutorials</a><li class="nav-list-item "> <a href="/tutorial_call/" class="nav-list-link">Call for Tutorials</a></ul><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Rising Stars Award category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <button class="nav-list-link-expander btn-reset" aria-label="toggle items in Rising Stars Award category" aria-pressed="false"> Rising Stars Award </button><ul class="nav-list"><li class="nav-list-item "> <a href="/rising_stars_guidelines/" class="nav-list-link">Call for Applications</a></ul><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Call for Papers category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <button class="nav-list-link-expander btn-reset" aria-label="toggle items in Call for Papers category" aria-pressed="false"> Call for Papers </button><ul class="nav-list"><li class="nav-list-item "> <a href="/tracks/" class="nav-list-link">Submission Tracks</a><li class="nav-list-item "> <a href="/subject_areas/" class="nav-list-link">Subject Areas</a><li class="nav-list-item "> <a href="/review_guidelines/" class="nav-list-link">Review Guidelines</a><li class="nav-list-item "> <a href="/code_of_conduct/" class="nav-list-link">Code of Conduct</a></ul><li class="nav-list-item"> <a href="/deadlines/" class="nav-list-link">Key Dates</a><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Organizers category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <button class="nav-list-link-expander btn-reset" aria-label="toggle items in Organizers category" aria-pressed="false"> Organizers </button><ul class="nav-list"><li class="nav-list-item "> <a href="/organization_committee/" class="nav-list-link">Organization Committee</a><li class="nav-list-item "> <a href="/advisory/" class="nav-list-link">Advisory Committee</a><li class="nav-list-item "> <a href="/area_chairs/" class="nav-list-link">Area Chairs</a></ul><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Conference Sponsors category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <button class="nav-list-link-expander btn-reset" aria-label="toggle items in Conference Sponsors category" aria-pressed="false"> Conference Sponsors </button><ul class="nav-list"><li class="nav-list-item "> <a href="/sponsors/" class="nav-list-link">Sponsors</a></ul><li class="nav-list-item"> <a href="/vision/" class="nav-list-link">Conference Vision</a><li class="nav-list-item"> <a href="/other_years/" class="nav-list-link">Past CPAL Websites</a></ul></nav><footer class="site-footer"> Connect: <br> <a href="mailto:pcs@cpal.cc"><img src=/assets/images/email.svg alt="Email icon"></a> <a href="https://twitter.com/CPALconf"><img src=/assets/images/twitter.svg alt="Twitter icon"></a> <a href="https://www.linkedin.com/company/conference-on-parsimony-and-learning-cpal/"><img src=/assets/images/linkedin.svg alt="Linkedin icon"></a> <br> <credit>Credit: <a href="https://github.com/just-the-docs/just-the-docs">theme</a></credit></footer></div><div class="main" id="top"><div id="main-header" class="main-header"><div class="search" role="search"><div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search CPAL" aria-label="Search CPAL" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label></div><div id="search-results" class="search-results"></div></div><nav aria-label="Auxiliary" class="aux-nav"><ul class="aux-nav-list"><li class="aux-nav-list-item"> <a href="https://cvent.me/X5aaar" class="site-button" > Registration </a><li class="aux-nav-list-item"> <a href="https://openreview.net/group?id=CPAL.cc/2025" class="site-button" > CPAL OpenReview </a></ul></nav></div><div id="main-content-wrap" class="main-content-wrap"><div id="main-content" class="main-content"><main><div class="splash"> <img src="/assets/images/stanford.jpg" alt="Splash photo of Stanford" /><div class="topleft"> Conference on Parsimony and Learning (CPAL)</div><div class="bottomright"> March 2025,&nbsp;Stanford</div></div><h1 id="keynote-speakers"> <a href="#keynote-speakers" class="anchor-heading" aria-labelledby="keynote-speakers"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Keynote Speakers</h1><p>Clicking a speaker’s photo will jump to their talk information below.</p><div style="clear: both; display: flex; flex-wrap: wrap; justify-content: center; max-width: 575px; column-gap: 10px;"><div class="speaker" style="width: 140px;"> <a href="/speakers/#richard-baraniuk"><img class="speaker-image" src="/assets/images/speakers/baraniuk.jpeg" alt="" /></a><div><h3 class="speaker-name no_anchor"> <a href="https://richb.rice.edu/">Richard Baraniuk</a></h3><p>Rice University</p></div></div><div class="speaker" style="width: 140px;"> <a href="/speakers/#alison-gopnik"><img class="speaker-image" src="/assets/images/speakers/gopnik.jpeg" alt="" /></a><div><h3 class="speaker-name no_anchor"> <a href="https://psychology.berkeley.edu/people/alison-gopnik">Alison Gopnik</a></h3><p>University of California, Berkeley</p></div></div><div class="speaker" style="width: 140px;"> <a href="/speakers/#fred-kjolstad"><img class="speaker-image" src="/assets/images/speakers/kjolstad.jpeg" alt="" /></a><div><h3 class="speaker-name no_anchor"> <a href="https://fredrikbk.com/">Fred Kjolstad</a></h3><p>Stanford University</p></div></div><div class="speaker" style="width: 140px;"> <a href="/speakers/#konrad-kording"><img class="speaker-image" src="/assets/images/speakers/kording.jpeg" alt="" /></a><div><h3 class="speaker-name no_anchor"> <a href="https://kordinglab.com/people/konrad_kording/index.html">Konrad Kording</a></h3><p>University of Pennsylvania</p></div></div><div class="speaker" style="width: 140px;"> <a href="/speakers/#jason-lee"><img class="speaker-image" src="/assets/images/speakers/lee.jpeg" alt="" /></a><div><h3 class="speaker-name no_anchor"> <a href="https://jasondlee88.github.io/">Jason Lee</a></h3><p>Princeton University</p></div></div><div class="speaker" style="width: 140px;"> <a href="/speakers/#yingyu-liang"><img class="speaker-image" src="/assets/images/speakers/liang.jpg" alt="" /></a><div><h3 class="speaker-name no_anchor"> <a href="https://yingyuliang.github.io/">Yingyu Liang</a></h3><p>University of Hong Kong, University of Wisconsin-Madison</p></div></div><div class="speaker" style="width: 140px;"> <a href="/speakers/#yuandong-tian"><img class="speaker-image" src="/assets/images/speakers/tian.png" alt="" /></a><div><h3 class="speaker-name no_anchor"> <a href="https://yuandong-tian.com/">Yuandong Tian</a></h3><p>Meta AI Research</p></div></div><div class="speaker" style="width: 140px;"> <a href="/speakers/#doris-tsao"><img class="speaker-image" src="/assets/images/speakers/tsao.jpeg" alt="" /></a><div><h3 class="speaker-name no_anchor"> <a href="https://tsaolab.berkeley.edu/">Doris Tsao</a></h3><p>University of California, Berkeley</p></div></div><div class="speaker" style="width: 140px;"> <a href="/speakers/#michael-unser"><img class="speaker-image" src="/assets/images/speakers/unser.jpeg" alt="" /></a><div><h3 class="speaker-name no_anchor"> <a href="https://bigwww.epfl.ch/unser/">Michael Unser</a></h3><p>École Polytechnique Fédérale de Lausanne (EPFL)</p></div></div></div><h1 id="talk-details"> <a href="#talk-details" class="anchor-heading" aria-labelledby="talk-details"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Talk Details</h1><h3 id="richard-baraniuk"> <a href="#richard-baraniuk" class="anchor-heading" aria-labelledby="richard-baraniuk"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://richb.rice.edu/">Richard Baraniuk</a></h3><p>Rice University</p><h4 id="title-parsimony-in-the-geometry-of-deep-learning"> <a href="#title-parsimony-in-the-geometry-of-deep-learning" class="anchor-heading" aria-labelledby="title-parsimony-in-the-geometry-of-deep-learning"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Title: Parsimony in the Geometry of Deep Learning</h4><h4 id="time-and-location-day-2-900-am-pt-simonyi-conference-center"> <a href="#time-and-location-day-2-900-am-pt-simonyi-conference-center" class="anchor-heading" aria-labelledby="time-and-location-day-2-900-am-pt-simonyi-conference-center"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Time and Location: <a href="/program_schedule/">Day 2, 9:00 AM PT</a>, Simonyi Conference Center</h4><h4 id="abstract"> <a href="#abstract" class="anchor-heading" aria-labelledby="abstract"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Abstract</h4><p>We study the geometry of deep learning through the lens of approximation theory via splines. The enabling insight is that a large class of deep networks can be written as a composition of continuous piecewise affine spline operators, which provides a powerful portal through which to interpret and analyze their inner workings. Our particular focus is the local geometry of the spline partition of the network’s input space, which opens up new avenues to study how deep networks parsimoniously organize signals in a hierarchical, multiscale fashion.</p><h4 id="bio"> <a href="#bio" class="anchor-heading" aria-labelledby="bio"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Bio</h4><p>Richard G. Baraniuk is the C. Sidney Burrus Professor of Electrical and Computer Engineering at Rice University and the Founding Director of OpenStax and SafeInsights. His research interests lie in new theory, algorithms, and hardware for machine learning, signal processing, and sensing. He is a Member of the National Academy of Engineering and American Academy of Arts and Sciences and a Fellow of the National Academy of Inventors, AAAS, and IEEE. He has received the DOD Vannevar Bush Faculty Fellow Award, the IEEE Jack S. Kilby Signal Processing Medal, the IEEE Signal Processing Society Technical Achievement and Society Awards, the Harold W. McGraw, Jr. Prize in Education, and the IEEE James H. Mulligan, Jr. Education Medal, among others.</p><h3 id="alison-gopnik"> <a href="#alison-gopnik" class="anchor-heading" aria-labelledby="alison-gopnik"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://psychology.berkeley.edu/people/alison-gopnik">Alison Gopnik</a></h3><p>University of California, Berkeley</p><h4 id="title-empowerment-gain-and-causal-model-construction"> <a href="#title-empowerment-gain-and-causal-model-construction" class="anchor-heading" aria-labelledby="title-empowerment-gain-and-causal-model-construction"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Title: Empowerment Gain and Causal Model Construction</h4><h4 id="time-and-location-day-2-1100-am-pt-simonyi-conference-center"> <a href="#time-and-location-day-2-1100-am-pt-simonyi-conference-center" class="anchor-heading" aria-labelledby="time-and-location-day-2-1100-am-pt-simonyi-conference-center"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Time and Location: <a href="/program_schedule/">Day 2, 11:00 AM PT</a>, Simonyi Conference Center</h4><h4 id="abstract-1"> <a href="#abstract-1" class="anchor-heading" aria-labelledby="abstract-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Abstract</h4><p>Learning about the causal structure of the world is a fundamental problem for human cognition. Causal models and especially causal learning have proved to be difficult for Large Models using standard techniques of deep learning. In contrast, cognitive scientists have applied advances in our formal understanding of causation in computer science, particularly within the Causal Bayes Net formalism, to understand human causal learning. In the very different tradition of reinforcement learning, researchers have described an intrinsic reward signal called “empowerment” which maximizes mutual information between actions and their outcomes. “Empowerment” may be an important bridge between classical Bayesian causal learning and reinforcement learning and may help to characterize causal learning in humans and enable it in machines. If an agent learns an accurate causal world model they will necessarily increase their empowerment, and increasing empowerment will lead to a more accurate causal world model. Empowerment may also explain distinctive empirical features of children’s causal learning, as well as providing a more tractable computational account of how that learning is possible.</p><h4 id="bio-1"> <a href="#bio-1" class="anchor-heading" aria-labelledby="bio-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Bio</h4><p>TBA</p><h3 id="fred-kjolstad"> <a href="#fred-kjolstad" class="anchor-heading" aria-labelledby="fred-kjolstad"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://fredrikbk.com/">Fred Kjolstad</a></h3><p>Stanford University</p><h4 id="title-plenary-talk-1"> <a href="#title-plenary-talk-1" class="anchor-heading" aria-labelledby="title-plenary-talk-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Title: Plenary Talk 1</h4><h4 id="time-and-location-day-3-900-am-pt-simonyi-conference-center"> <a href="#time-and-location-day-3-900-am-pt-simonyi-conference-center" class="anchor-heading" aria-labelledby="time-and-location-day-3-900-am-pt-simonyi-conference-center"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Time and Location: <a href="/program_schedule/">Day 3, 9:00 AM PT</a>, Simonyi Conference Center</h4><h4 id="abstract-2"> <a href="#abstract-2" class="anchor-heading" aria-labelledby="abstract-2"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Abstract</h4><p>TBA</p><h4 id="bio-2"> <a href="#bio-2" class="anchor-heading" aria-labelledby="bio-2"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Bio</h4><p>TBA</p><h3 id="konrad-kording"> <a href="#konrad-kording" class="anchor-heading" aria-labelledby="konrad-kording"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://kordinglab.com/people/konrad_kording/index.html">Konrad Kording</a></h3><p>University of Pennsylvania</p><h4 id="title-how-can-we-succeed-with-parsimonious-models-in-a-world-that-is-not-so-parsimonious"> <a href="#title-how-can-we-succeed-with-parsimonious-models-in-a-world-that-is-not-so-parsimonious" class="anchor-heading" aria-labelledby="title-how-can-we-succeed-with-parsimonious-models-in-a-world-that-is-not-so-parsimonious"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Title: How Can We Succeed With Parsimonious Models in a World that is Not So Parsimonious</h4><h4 id="time-and-location-day-4-130-pm-pt-simonyi-conference-center"> <a href="#time-and-location-day-4-130-pm-pt-simonyi-conference-center" class="anchor-heading" aria-labelledby="time-and-location-day-4-130-pm-pt-simonyi-conference-center"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Time and Location: <a href="/program_schedule/">Day 4, 1:30 PM PT</a>, Simonyi Conference Center</h4><h4 id="abstract-3"> <a href="#abstract-3" class="anchor-heading" aria-labelledby="abstract-3"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Abstract</h4><p>Many interesting parts of the world, such as ecosystems, economies, psychology, cells and brains are, deep down, very much not explainable in a parsimonious way. And yet, humans, quite successfully, describe the world around them as it it were, and machine learning models are apparently internally quite parsimonious. I will comment on the statistical nature of the world around us and why we may succeed well assuming parsimony.</p><h4 id="bio-3"> <a href="#bio-3" class="anchor-heading" aria-labelledby="bio-3"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Bio</h4><p>TBA</p><h3 id="jason-lee"> <a href="#jason-lee" class="anchor-heading" aria-labelledby="jason-lee"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://jasondlee88.github.io/">Jason Lee</a></h3><p>Princeton University</p><h4 id="title-emergence-and-scaling-laws-for-sgd-learning-and-learning-compositional-functions-with-transformers"> <a href="#title-emergence-and-scaling-laws-for-sgd-learning-and-learning-compositional-functions-with-transformers" class="anchor-heading" aria-labelledby="title-emergence-and-scaling-laws-for-sgd-learning-and-learning-compositional-functions-with-transformers"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Title: Emergence and Scaling Laws for SGD Learning and Learning Compositional Functions with Transformers</h4><h4 id="time-and-location-day-2-300-pm-pt-simonyi-conference-center"> <a href="#time-and-location-day-2-300-pm-pt-simonyi-conference-center" class="anchor-heading" aria-labelledby="time-and-location-day-2-300-pm-pt-simonyi-conference-center"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Time and Location: <a href="/program_schedule/">Day 2, 3:00 PM PT</a>, Simonyi Conference Center</h4><h4 id="abstract-4"> <a href="#abstract-4" class="anchor-heading" aria-labelledby="abstract-4"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Abstract</h4><p>This is a two part talk. (1) We study the sample and time complexity of online stochastic gradient descent (SGD) for learning a two-layer neural network with $P$ orthogonal neurons on isotropic Gaussian data. We focus on the challenging regime \(P\gg 1\) and allow for large condition number in the second-layer, covering the power-law scaling \(a_p= p^{-\beta}\) as a special case. We characterize the SGD dynamics for the training of a student two-layer network to minimize the squared loss, and identify sharp transition times for the recovery of each signal direction. In the power-law setting, our analysis entails that while the learning of individual teacher neurons exhibits abrupt phase transitions, the juxtaposition of \(P\gg 1\) emergent learning curves at different timescales leads to a smooth scaling law in the cumulative squared loss. (2) Transformer-based language models have demonstrated impressive capabilities across a range of complex reasoning tasks. Prior theoretical work exploring the expressive power of transformers has shown that they can efficiently perform multi-step reasoning tasks. However, the learnability of such constructions, particularly the conditions on the data distribution that enable efficient learning via SGD, remains an open question. Towards answering this question, we study the learnability of a task called \(k\)-fold composition, which requires computing an interleaved composition of \(k\) input permutations and \(k\) hidden permutations, and can be expressed by a transformer with \(O(\log k)\) layers. We show that this function class can be efficiently learned, with runtime and sample complexity polynomial in \(k\), by gradient descent on an \(O(\log k)\)-depth transformer via mixed training: one in which data consists of \(k'\)-fold composition functions with \(k' \le k\) trained on simultaneously. Our work sheds light on the necessity and sufficiency of having both easy and hard examples in the data distribution for transformers to learn complex compositional tasks. A corresponding statistical query lower bound shows that without mixed training requires \(\exp(k)\) samples and time.</p><h4 id="bio-4"> <a href="#bio-4" class="anchor-heading" aria-labelledby="bio-4"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Bio</h4><p>TBA</p><h3 id="yingyu-liang"> <a href="#yingyu-liang" class="anchor-heading" aria-labelledby="yingyu-liang"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://yingyuliang.github.io/">Yingyu Liang</a></h3><p>University of Hong Kong, University of Wisconsin-Madison</p><h4 id="title-towards-better-understanding-of-deep-learning-via-investigations-of-the-learning-dynamics"> <a href="#title-towards-better-understanding-of-deep-learning-via-investigations-of-the-learning-dynamics" class="anchor-heading" aria-labelledby="title-towards-better-understanding-of-deep-learning-via-investigations-of-the-learning-dynamics"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Title: Towards Better Understanding of Deep Learning via Investigations of the Learning Dynamics</h4><h4 id="time-and-location-day-4-900-am-pt-simonyi-conference-center"> <a href="#time-and-location-day-4-900-am-pt-simonyi-conference-center" class="anchor-heading" aria-labelledby="time-and-location-day-4-900-am-pt-simonyi-conference-center"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Time and Location: <a href="/program_schedule/">Day 4, 9:00 AM PT</a>, Simonyi Conference Center</h4><h4 id="abstract-5"> <a href="#abstract-5" class="anchor-heading" aria-labelledby="abstract-5"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Abstract</h4><p>Compared to the unprecedented empirical success of deep learning, theoretical understanding largely lags behind. In particular, traditional tools are inadequate for analyzing the optimization and generalization in deep learning. This talk will discuss the unique and novel challenges in this direction, via a few case studies: the neural tangent kernel (NTK) approach, feature learning beyond NTK, and different in-context learning behavior of larger language models.</p><h4 id="bio-5"> <a href="#bio-5" class="anchor-heading" aria-labelledby="bio-5"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Bio</h4><p>TBA</p><h3 id="yuandong-tian"> <a href="#yuandong-tian" class="anchor-heading" aria-labelledby="yuandong-tian"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://yuandong-tian.com/">Yuandong Tian</a></h3><p>Meta AI Research</p><h4 id="title-emergence-of-various-structures-during-transformer-training-via-the-lens-of-training-dynamics"> <a href="#title-emergence-of-various-structures-during-transformer-training-via-the-lens-of-training-dynamics" class="anchor-heading" aria-labelledby="title-emergence-of-various-structures-during-transformer-training-via-the-lens-of-training-dynamics"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Title: Emergence of Various Structures During Transformer Training via the Lens of Training Dynamics</h4><h4 id="time-and-location-day-4-400-pm-pt-simonyi-conference-center"> <a href="#time-and-location-day-4-400-pm-pt-simonyi-conference-center" class="anchor-heading" aria-labelledby="time-and-location-day-4-400-pm-pt-simonyi-conference-center"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Time and Location: <a href="/program_schedule/">Day 4, 4:00 PM PT</a>, Simonyi Conference Center</h4><h4 id="abstract-6"> <a href="#abstract-6" class="anchor-heading" aria-labelledby="abstract-6"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Abstract</h4><p>Large Language Models (LLMs) have demonstrated remarkable performance across diverse applications. However, most empirical works treat the underlying architecture as black boxes, and it remains a mystery what representation the model learns and how it learns. I will cover two aspects of our theoretical analysis, including the training dynamics of self-attention layers when learning Transformers (i.e. how it learns), as well as intriguing structure of the resulting representations (i.e. what it learns), which includes not only basic structure of sparsity and low rankness, but also more complicated ones such as algebraic, hierarchical and spectral structures. Our analysis provides insights into the complicated nonlinear learning process beyond the scope of traditional learning theory, leads to development of novel empirical approaches and shed light on a possible unification of neural and symbolic representations.</p><h4 id="bio-6"> <a href="#bio-6" class="anchor-heading" aria-labelledby="bio-6"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Bio</h4><p>TBA</p><h3 id="doris-tsao"> <a href="#doris-tsao" class="anchor-heading" aria-labelledby="doris-tsao"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://tsaolab.berkeley.edu/">Doris Tsao</a></h3><p>University of California, Berkeley</p><h4 id="title-plenary-talk-4"> <a href="#title-plenary-talk-4" class="anchor-heading" aria-labelledby="title-plenary-talk-4"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Title: Plenary Talk 4</h4><h4 id="time-and-location-day-3-300-pm-pt-simonyi-conference-center"> <a href="#time-and-location-day-3-300-pm-pt-simonyi-conference-center" class="anchor-heading" aria-labelledby="time-and-location-day-3-300-pm-pt-simonyi-conference-center"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Time and Location: <a href="/program_schedule/">Day 3, 3:00 PM PT</a>, Simonyi Conference Center</h4><h4 id="abstract-7"> <a href="#abstract-7" class="anchor-heading" aria-labelledby="abstract-7"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Abstract</h4><p>TBA</p><h4 id="bio-7"> <a href="#bio-7" class="anchor-heading" aria-labelledby="bio-7"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Bio</h4><p>TBA</p><h3 id="michael-unser"> <a href="#michael-unser" class="anchor-heading" aria-labelledby="michael-unser"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://bigwww.epfl.ch/unser/">Michael Unser</a></h3><p>École Polytechnique Fédérale de Lausanne (EPFL)</p><h4 id="title-are-the-methods-of-convex-analysis-competitive-with-deep-neural-networks"> <a href="#title-are-the-methods-of-convex-analysis-competitive-with-deep-neural-networks" class="anchor-heading" aria-labelledby="title-are-the-methods-of-convex-analysis-competitive-with-deep-neural-networks"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Title: Are the Methods of Convex Analysis Competitive with Deep Neural Networks?</h4><h4 id="time-and-location-day-3-1130-am-pt-simonyi-conference-center"> <a href="#time-and-location-day-3-1130-am-pt-simonyi-conference-center" class="anchor-heading" aria-labelledby="time-and-location-day-3-1130-am-pt-simonyi-conference-center"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Time and Location: <a href="/program_schedule/">Day 3, 11:30 AM PT</a>, Simonyi Conference Center</h4><h4 id="abstract-8"> <a href="#abstract-8" class="anchor-heading" aria-labelledby="abstract-8"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Abstract</h4><p>Computational imaging is currently dominated by two paradigms. Traditional variational methods, supported by well-established theory, provide guarantees for convergence, stability, and signal recovery from limited measurements, as in compressed sensing. In contrast, deep neural network methods generally achieve superior image reconstruction but suffer from a lack of robustness (tendency to hallucinate) and theoretical understanding. This raises a fundamental question: Can variational methods be improved by learning the regularizer while maintaining their theoretical guarantees? To address this, we introduce a general framework for image reconstruction under the constraints of amplitude-equivariance and convexity. We demonstrate that polyhedral norms enable universality, allowing for the design of trainable regularization architectures. These architectures outperform traditional sparsity-based methods, and help us bridge the gap between theoretical rigor and practical performance in computational imaging.</p><h4 id="bio-8"> <a href="#bio-8" class="anchor-heading" aria-labelledby="bio-8"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Bio</h4><p>Michael Unser is Full Professor at the EPFL and the academic director of EPFL’s Center for Imaging, Lausanne, Switzerland. His primary areas of investigation are biomedical imaging and applied functional analysis. He is internationally recognized for his research contributions to sampling theory, wavelets, the use of splines for image processing, and computational bioimaging. He has published over 400 journal papers on those topics. Prof. Unser is a fellow of the IEEE (1999), an EURASIP fellow (2009), and a member of the Swiss Academy of Engineering Sciences. He is the recipient of several international prizes including five IEEE-SPS Best Paper Awards, two Technical Achievement Awards from the IEEE (2008 SPS and EMBS 2010), the Technical Achievement Award from EURASIP (2018), and the IEEE-EMBS Career Achievement Award (2020). He was awarded three ERC AdG grants: FUNSP (2011-2016), GlobalBioIm (2016-2021), and FunLearn (2021-2026) in succession, with the ERC funding scheme being the most competitive one in Europe.</p></main></div></div><div class="search-overlay"></div></div>
