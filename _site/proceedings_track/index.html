<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><title>Proceedings Track | Conference on Parsimony and Learning (CPAL)</title><meta name="generator" content="Jekyll v3.9.0" /><meta property="og:title" content="Proceedings Track" /><meta property="og:locale" content="en_US" /><meta name="description" content="Accepted papers for CPAL 2024 Proceedings Track" /><meta property="og:description" content="Accepted papers for CPAL 2024 Proceedings Track" /><link rel="canonical" href="https://cpal.cc/proceedings_track/" /><meta property="og:url" content="https://cpal.cc/proceedings_track/" /><meta property="og:site_name" content="Conference on Parsimony and Learning (CPAL)" /><meta property="og:image" content="https://cpal.cc/assets/images/card.png" /><meta property="og:type" content="website" /><meta name="twitter:card" content="summary_large_image" /><meta property="twitter:image" content="https://cpal.cc/assets/images/card.png" /><meta property="twitter:title" content="Proceedings Track" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"Accepted papers for CPAL 2024 Proceedings Track","headline":"Proceedings Track","image":"https://cpal.cc/assets/images/card.png","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://cpal.cc/assets/images/logo.svg"}},"url":"https://cpal.cc/proceedings_track/"}</script><body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"><title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"><title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"><title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"><title id="svg-external-link-title">(external link)</title><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"><title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"><title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-copy" viewBox="0 0 16 16"><title>Copy</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/><path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"><title>Copied</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"><path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg><div class="side-bar"><div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"><div class="site-logo" role="img" aria-label="Conference on Parsimony and Learning (CPAL)"></div></a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </a></div><nav aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item"> <a href="/" class="nav-list-link">Home</a><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Register & Attend category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <button class="nav-list-link-expander btn-reset" aria-label="toggle items in Register & Attend category" aria-pressed="false"> Register & Attend </button><ul class="nav-list"><li class="nav-list-item "> <a href="/registration/" class="nav-list-link">Registration</a><li class="nav-list-item "> <a href="/visa/" class="nav-list-link">Travel: Visa Information</a><li class="nav-list-item "> <a href="/hotels/" class="nav-list-link">Travel: Hotels</a></ul><li class="nav-list-item active"><button class="nav-list-expander btn-reset" aria-label="toggle items in Accepted Papers category" aria-pressed="true"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <button class="nav-list-link-expander btn-reset" aria-label="toggle items in Accepted Papers category" aria-pressed="true"> Accepted Papers </button><ul class="nav-list"><li class="nav-list-item active"> <a href="/proceedings_track/" class="nav-list-link active">Proceedings Track</a><li class="nav-list-item "> <a href="/spotlight_track/" class="nav-list-link">Spotlight Track</a></ul><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Conference Program category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <button class="nav-list-link-expander btn-reset" aria-label="toggle items in Conference Program category" aria-pressed="false"> Conference Program </button><ul class="nav-list"><li class="nav-list-item "> <a href="/program_schedule/" class="nav-list-link">Program at a Glance</a><li class="nav-list-item "> <a href="/orals/" class="nav-list-link">Oral Presentations</a><li class="nav-list-item "> <a href="/posters/" class="nav-list-link">Poster Presentations</a><li class="nav-list-item "> <a href="/rising_stars_presentations/" class="nav-list-link">Rising Stars Presentations</a></ul><li class="nav-list-item"> <a href="/speakers/" class="nav-list-link">Keynote Speakers</a><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Tutorials category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <button class="nav-list-link-expander btn-reset" aria-label="toggle items in Tutorials category" aria-pressed="false"> Tutorials </button><ul class="nav-list"><li class="nav-list-item "> <a href="/tutorial_info/" class="nav-list-link">List of Tutorials</a><li class="nav-list-item "> <a href="/tutorial_call/" class="nav-list-link">Call for Tutorials</a></ul><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Rising Stars Award category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <button class="nav-list-link-expander btn-reset" aria-label="toggle items in Rising Stars Award category" aria-pressed="false"> Rising Stars Award </button><ul class="nav-list"><li class="nav-list-item "> <a href="/rising_stars_guidelines/" class="nav-list-link">Call for Applications</a></ul><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Call for Papers category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <button class="nav-list-link-expander btn-reset" aria-label="toggle items in Call for Papers category" aria-pressed="false"> Call for Papers </button><ul class="nav-list"><li class="nav-list-item "> <a href="/tracks/" class="nav-list-link">Submission Tracks</a><li class="nav-list-item "> <a href="/subject_areas/" class="nav-list-link">Subject Areas</a><li class="nav-list-item "> <a href="/review_guidelines/" class="nav-list-link">Review Guidelines</a><li class="nav-list-item "> <a href="/code_of_conduct/" class="nav-list-link">Code of Conduct</a></ul><li class="nav-list-item"> <a href="/deadlines/" class="nav-list-link">Key Dates</a><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Organizers category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <button class="nav-list-link-expander btn-reset" aria-label="toggle items in Organizers category" aria-pressed="false"> Organizers </button><ul class="nav-list"><li class="nav-list-item "> <a href="/organization_committee/" class="nav-list-link">Organization Committee</a><li class="nav-list-item "> <a href="/advisory/" class="nav-list-link">Advisory Committee</a><li class="nav-list-item "> <a href="/area_chairs/" class="nav-list-link">Area Chairs</a></ul><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Conference Sponsors category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <button class="nav-list-link-expander btn-reset" aria-label="toggle items in Conference Sponsors category" aria-pressed="false"> Conference Sponsors </button><ul class="nav-list"><li class="nav-list-item "> <a href="/sponsors/" class="nav-list-link">Sponsors</a><li class="nav-list-item "> <a href="/sponsorship_opportunities/" class="nav-list-link">Sponsorship Opportunities</a></ul><li class="nav-list-item"> <a href="/vision/" class="nav-list-link">Conference Vision</a><li class="nav-list-item"> <a href="/other_years/" class="nav-list-link">Past CPAL Websites</a></ul></nav><footer class="site-footer"> Connect: <br> <a href="mailto:pcs@cpal.cc"><img src=/assets/images/email.svg alt="Email icon"></a> <a href="https://twitter.com/CPALconf"><img src=/assets/images/twitter.svg alt="Twitter icon"></a> <a href="https://www.linkedin.com/company/conference-on-parsimony-and-learning-cpal/"><img src=/assets/images/linkedin.svg alt="Linkedin icon"></a> <br> <credit>Credit: <a href="https://github.com/just-the-docs/just-the-docs">theme</a></credit></footer></div><div class="main" id="top"><div id="main-header" class="main-header"><div class="search" role="search"><div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search CPAL" aria-label="Search CPAL" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label></div><div id="search-results" class="search-results"></div></div><nav aria-label="Auxiliary" class="aux-nav"><ul class="aux-nav-list"><li class="aux-nav-list-item"> <a href="https://cvent.me/X5aaar" class="site-button" > Registration </a><li class="aux-nav-list-item"> <a href="https://openreview.net/group?id=CPAL.cc/2025" class="site-button" > CPAL OpenReview </a></ul></nav></div><div id="main-content-wrap" class="main-content-wrap"><nav aria-label="Breadcrumb" class="breadcrumb-nav"><ol class="breadcrumb-nav-list"><li class="breadcrumb-nav-list-item"><a href="/accepted_papers/">Accepted Papers</a><li class="breadcrumb-nav-list-item"><span>Proceedings Track</span></ol></nav><div id="main-content" class="main-content"><main><div class="splash"> <img src="/assets/images/stanford.jpg" alt="Splash photo of Stanford" /><div class="topleft"> Conference on Parsimony and Learning (CPAL)</div><div class="bottomright"> March 2025,&nbsp;Stanford</div></div><h1 id="proceedings-track-accepted-papers"> <a href="#proceedings-track-accepted-papers" class="anchor-heading" aria-labelledby="proceedings-track-accepted-papers"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Proceedings Track: Accepted Papers</h1><h2 id="presentation-format"> <a href="#presentation-format" class="anchor-heading" aria-labelledby="presentation-format"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Presentation Format</h2><p>Accepted Proceedings Track papers are presented as <a href="/posters">posters</a> at CPAL 2025. A select number of accepted Proceedings Track papers will be presented as <a href="/orals">orals</a>; they are labeled below with <strong><em>(Oral)</em></strong>. See the <a href="/program_schedule/">full program</a> for the precise time and location of each oral and poster session.</p><h3 id="towards-vector-optimization-on-low-dimensional-vector-symbolic-architecture"> <a href="#towards-vector-optimization-on-low-dimensional-vector-symbolic-architecture" class="anchor-heading" aria-labelledby="towards-vector-optimization-on-low-dimensional-vector-symbolic-architecture"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=08PRND19BY">Towards Vector Optimization on Low-Dimensional Vector Symbolic Architecture</a></h3><p>Shijin Duan, Yejia Liu, Gaowen Liu, Ramana Rao Kompella, Shaolei Ren, Xiaolin Xu</p><p class="fs-2">Keywords: <em>Vector Symbolic Architecture, Batch Normalization, Knowledge Distillation</em></p><h3 id="sgd-with-weight-decay-secretly-minimizes-the-ranks-of-your-neural-networks"> <a href="#sgd-with-weight-decay-secretly-minimizes-the-ranks-of-your-neural-networks" class="anchor-heading" aria-labelledby="sgd-with-weight-decay-secretly-minimizes-the-ranks-of-your-neural-networks"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=0LzE9AROwD">SGD with Weight Decay Secretly Minimizes the Ranks of Your Neural Networks</a></h3><p>Tomer Galanti, Zachary S Siegel, Aparna Gupte, Tomaso A Poggio</p><p class="fs-2">Keywords: <em>Low-Rank, SGD, Implicit Bias, Rank, Rank Minimization, Weight Decay</em></p><h3 id="explaining-and-mitigating-the-modality-gap-in-contrastive-multimodal-learning"> <a href="#explaining-and-mitigating-the-modality-gap-in-contrastive-multimodal-learning" class="anchor-heading" aria-labelledby="explaining-and-mitigating-the-modality-gap-in-contrastive-multimodal-learning"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=2sThreW73a">Explaining and Mitigating the Modality Gap in Contrastive Multimodal Learning</a></h3><p>Can Yaras, Siyi Chen, Peng Wang, Qing Qu</p><p class="fs-2">Keywords: <em>multimodal learning, modality gap, contrastive learning</em></p><h3 id="collaborative-and-efficient-personalization-with-mixtures-of-adaptors"> <a href="#collaborative-and-efficient-personalization-with-mixtures-of-adaptors" class="anchor-heading" aria-labelledby="collaborative-and-efficient-personalization-with-mixtures-of-adaptors"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=3J6AXM2HfN">Collaborative and Efficient Personalization with Mixtures of Adaptors</a></h3><p>Abdulla Jasem Almansoori, Samuel Horváth, Martin Takáč</p><p class="fs-2">Keywords: <em>federated learning, personalization, multi-task learning, clustering, parameter-efficient</em></p><h3 id="are-all-layers-created-equal-a-neural-collapse-perspective"> <a href="#are-all-layers-created-equal-a-neural-collapse-perspective" class="anchor-heading" aria-labelledby="are-all-layers-created-equal-a-neural-collapse-perspective"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=5eHpefiK8W">Are all layers created equal: A neural collapse perspective</a></h3><p>Jinxin Zhou, Jiachen Jiang, Zhihui Zhu</p><p class="fs-2">Keywords: <em>Deep Learning, Neural Collapse, Robustness, Generalization, Memorization, Understanding</em></p><h3 id="white-box-error-correction-code-transformer"> <a href="#white-box-error-correction-code-transformer" class="anchor-heading" aria-labelledby="white-box-error-correction-code-transformer"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=6lfnSzJ5qE">White-box Error Correction Code Transformer</a></h3><p>Ziyan Zheng, Chin Wa Lau, Nian Guo, Xiang Shi, Shao-Lun Huang</p><p class="fs-2">Keywords: <em>Error Correction Codes, Neural Decoder, White-box Transformer, Sparse Rate Reduction, Tanner Graph</em></p><h3 id="on-how-iterative-magnitude-pruning-discovers-local-receptive-fields-in-fully-connected-neural-networks"> <a href="#on-how-iterative-magnitude-pruning-discovers-local-receptive-fields-in-fully-connected-neural-networks" class="anchor-heading" aria-labelledby="on-how-iterative-magnitude-pruning-discovers-local-receptive-fields-in-fully-connected-neural-networks"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=B936pXBrz5">On How Iterative Magnitude Pruning Discovers Local Receptive Fields in Fully Connected Neural Networks</a></h3><p>William T Redman, Zhangyang Wang, Alessandro Ingrosso, Sebastian Goldt</p><p class="fs-2">Keywords: <em>iterative magnitude pruning, lottery tickets, sparse machine learning, gaussian statistics</em></p><h3 id="hamiltonian-mechanics-of-feature-learning-bottleneck-structure-in-leaky-resnets-oral"> <a href="#hamiltonian-mechanics-of-feature-learning-bottleneck-structure-in-leaky-resnets-oral" class="anchor-heading" aria-labelledby="hamiltonian-mechanics-of-feature-learning-bottleneck-structure-in-leaky-resnets-oral"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=C8OsIiVcyC">Hamiltonian Mechanics of Feature Learning: Bottleneck Structure in Leaky ResNets</a> <strong><em>(Oral)</em></strong></h3><p>Arthur Jacot, Alexandre Kaiser</p><p class="fs-2">Keywords: <em>Low-rank bias, NeuralODE, Hamiltonian, Bottleneck structure</em></p><h3 id="streaming-kernel-pca-algorithm-with-small-space"> <a href="#streaming-kernel-pca-algorithm-with-small-space" class="anchor-heading" aria-labelledby="streaming-kernel-pca-algorithm-with-small-space"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=Gfl6APFUri">Streaming Kernel PCA Algorithm With Small Space</a></h3><p>Yichuan Deng, Jiangxuan Long, Zhao Song, Zifan Wang, Han Zhang</p><p class="fs-2">Keywords: <em>Principal Component Analysis, Kernel Method, Streaming Algorithm</em></p><h3 id="sufficient-and-necessary-explanations-and-what-lies-in-between-oral"> <a href="#sufficient-and-necessary-explanations-and-what-lies-in-between-oral" class="anchor-heading" aria-labelledby="sufficient-and-necessary-explanations-and-what-lies-in-between-oral"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=H43BmpeJII">Sufficient and Necessary Explanations (and What Lies in Between)</a> <strong><em>(Oral)</em></strong></h3><p>Beepul Bharti, Paul Yi, Jeremias Sulam</p><p class="fs-2">Keywords: <em>interpretability, explainability</em></p><h3 id="progressive-gradient-flow-for-robust-nm-sparsity-training-in-transformers-oral"> <a href="#progressive-gradient-flow-for-robust-nm-sparsity-training-in-transformers-oral" class="anchor-heading" aria-labelledby="progressive-gradient-flow-for-robust-nm-sparsity-training-in-transformers-oral"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=HJjauwys0B">Progressive Gradient Flow for Robust N:M Sparsity Training in Transformers</a> <strong><em>(Oral)</em></strong></h3><p>Abhimanyu Rajeshkumar Bambhaniya, Amir Yazdanbakhsh, Suvinay Subramanian, Sheng-Chun Kao, Shivani Agrawal, Utku Evci, Tushar Krishna</p><p class="fs-2">Keywords: <em>N:M structured sparsity, sparsity, model compression, attention-based models, sparse training recipe</em></p><h3 id="agenthpo-large-language-model-agent-for--hyper-parameter-optimization"> <a href="#agenthpo-large-language-model-agent-for--hyper-parameter-optimization" class="anchor-heading" aria-labelledby="agenthpo-large-language-model-agent-for--hyper-parameter-optimization"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=HU3yfXcoKU">AgentHPO: Large Language Model Agent for Hyper-Parameter Optimization</a></h3><p>Siyi Liu, Chen Gao, Yong Li</p><p class="fs-2">Keywords: <em>Large Language Models, Agent, Hyperparameter Optimization</em></p><h3 id="sparse-moe-as-a-new-treatment-addressing-forgetting-fitting-learning-issues-in-multi-modal-multi-task-learning"> <a href="#sparse-moe-as-a-new-treatment-addressing-forgetting-fitting-learning-issues-in-multi-modal-multi-task-learning" class="anchor-heading" aria-labelledby="sparse-moe-as-a-new-treatment-addressing-forgetting-fitting-learning-issues-in-multi-modal-multi-task-learning"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=IFfyezixou">Sparse MoE as a New Treatment: Addressing Forgetting, Fitting, Learning Issues in Multi-Modal Multi-Task Learning</a></h3><p>Jie Peng, Sukwon Yun, Kaixiong Zhou, Ruida Zhou, Thomas Hartvigsen, Yanyong Zhang, Zhangyang Wang, Tianlong Chen</p><p class="fs-2">Keywords: <em>transformer, sparse mixture-of-experts, multi-modal learning, multi-task learning</em></p><h3 id="exact-and-rich-feature-learning-dynamics-of-two-layer-linear-networks"> <a href="#exact-and-rich-feature-learning-dynamics-of-two-layer-linear-networks" class="anchor-heading" aria-labelledby="exact-and-rich-feature-learning-dynamics-of-two-layer-linear-networks"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=J7dZuX0DGI">Exact and Rich Feature Learning Dynamics of Two-Layer Linear Networks</a></h3><p>Wei Huang, Wuyang Chen, zhiqiang xu, Zhangyang Wang, Taiji Suzuki</p><p class="fs-2">Keywords: <em>Neural networks dyanmics, Feature Learning, Optimization</em></p><h3 id="vanishing-feature-diagnosing-model-merging-and-beyond-oral"> <a href="#vanishing-feature-diagnosing-model-merging-and-beyond-oral" class="anchor-heading" aria-labelledby="vanishing-feature-diagnosing-model-merging-and-beyond-oral"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=KBSh5ChQIo">Vanishing Feature: Diagnosing Model Merging and Beyond</a> <strong><em>(Oral)</em></strong></h3><p>Xingyu Qu, Samuel Horváth</p><p class="fs-2">Keywords: <em>Model Merging, Efficiency, Deep Learning, Efficient Deep Learning</em></p><h3 id="q-galore-quantized-galore-with-int4-projection-and-layer-adaptive-low-rank-gradients"> <a href="#q-galore-quantized-galore-with-int4-projection-and-layer-adaptive-low-rank-gradients" class="anchor-heading" aria-labelledby="q-galore-quantized-galore-with-int4-projection-and-layer-adaptive-low-rank-gradients"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=KTAPk6c2hl">Q-GaLore: Quantized GaLore with INT4 Projection and Layer-Adaptive Low-Rank Gradients</a></h3><p>Zhenyu Zhang, AJAY KUMAR JAISWAL, Lu Yin, Shiwei Liu, Jiawei Zhao, Yuandong Tian, Zhangyang Wang</p><p class="fs-2">Keywords: <em>Large Language Models; Memory Efficient Training; Low Rank</em></p><h3 id="enhancing-video-representation-learning-with-temporal-differentiation"> <a href="#enhancing-video-representation-learning-with-temporal-differentiation" class="anchor-heading" aria-labelledby="enhancing-video-representation-learning-with-temporal-differentiation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=NgR6hYd3Xw">Enhancing Video Representation Learning with Temporal Differentiation</a></h3><p>Siyi Chen, Minkyu Choi, Zesen Zhao, Kuan Han, Qing Qu, Zhongming Liu</p><p class="fs-2">Keywords: <em>video representation learning, physics-inspired</em></p><h3 id="fedosaa-improving-federated-learning-with-one-step-anderson-acceleration"> <a href="#fedosaa-improving-federated-learning-with-one-step-anderson-acceleration" class="anchor-heading" aria-labelledby="fedosaa-improving-federated-learning-with-one-step-anderson-acceleration"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=OoYcaWhfwB">FedOSAA: Improving Federated Learning with One-Step Anderson Acceleration</a></h3><p>Xue Feng, M. Paul Laiu, Thomas Strohmer</p><p class="fs-2">Keywords: <em>federated learning, quasi-Newton methods, Anderson acceleration</em></p><h3 id="closure-discovery-for-coarse-grained-partial-differential-equations-using-grid-based-reinforcement-learning-oral"> <a href="#closure-discovery-for-coarse-grained-partial-differential-equations-using-grid-based-reinforcement-learning-oral" class="anchor-heading" aria-labelledby="closure-discovery-for-coarse-grained-partial-differential-equations-using-grid-based-reinforcement-learning-oral"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=Pve4Pg0A1v">Closure Discovery for Coarse-Grained Partial Differential Equations Using Grid-based Reinforcement Learning</a> <strong><em>(Oral)</em></strong></h3><p>Jan-Philipp von Bassewitz, Sebastian Kaltenbach, Petros Koumoutsakos</p><p class="fs-2">Keywords: <em>Closure Discovery, Inductive Bias, Multi-Agent Reinforcement Learning</em></p><h3 id="fast-and-efficient-matching-algorithm-with-deadline-instances"> <a href="#fast-and-efficient-matching-algorithm-with-deadline-instances" class="anchor-heading" aria-labelledby="fast-and-efficient-matching-algorithm-with-deadline-instances"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=TIneXGrWZt">Fast and Efficient Matching Algorithm with Deadline Instances</a></h3><p>Zhao Song, Weixin Wang, Chenbo Yin, Junze Yin</p><p class="fs-2">Keywords: <em>online weighted matching problem, sketching</em></p><h3 id="learning-effective-dynamics-across-spatio-temporal-scales-of-complex-flows"> <a href="#learning-effective-dynamics-across-spatio-temporal-scales-of-complex-flows" class="anchor-heading" aria-labelledby="learning-effective-dynamics-across-spatio-temporal-scales-of-complex-flows"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=TU9e5yChcU">Learning Effective Dynamics across Spatio-Temporal Scales of Complex Flows</a></h3><p>Han Gao, Sebastian Kaltenbach, Petros Koumoutsakos</p><p class="fs-2">Keywords: <em>Learned Effective Dynamics, Reduced-Order Modeling, Multiscale Systems, Turbulent Flows</em></p><h3 id="reccrysformer-refined-protein-structural-prediction-from-3d-patterson-maps-via-recycling-training-runs"> <a href="#reccrysformer-refined-protein-structural-prediction-from-3d-patterson-maps-via-recycling-training-runs" class="anchor-heading" aria-labelledby="reccrysformer-refined-protein-structural-prediction-from-3d-patterson-maps-via-recycling-training-runs"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=U9DhMKzXPT">RecCrysFormer: Refined Protein Structural Prediction from 3D Patterson Maps via Recycling Training Runs</a></h3><p>Tom Pan, Evan Dramko, Mitchell D. Miller, George N Phillips Jr., Anastasios Kyrillidis</p><p class="fs-2">Keywords: <em>Protein Structural Prediction, Transformers, Patterson Maps</em></p><h3 id="taming-sensitive-weights--noise-perturbation-fine-tuning-for-robust-llm-quantization"> <a href="#taming-sensitive-weights--noise-perturbation-fine-tuning-for-robust-llm-quantization" class="anchor-heading" aria-labelledby="taming-sensitive-weights--noise-perturbation-fine-tuning-for-robust-llm-quantization"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=VehapTAftQ">Taming Sensitive Weights : Noise Perturbation Fine-tuning for Robust LLM Quantization</a></h3><p>DONGWEI WANG, Huanrui Yang</p><p class="fs-2">Keywords: <em>LLM quantization, Hessian trace, Noise-aware finetuning</em></p><h3 id="adversarially-robust-spiking-neural-networks-with-sparse-connectivity"> <a href="#adversarially-robust-spiking-neural-networks-with-sparse-connectivity" class="anchor-heading" aria-labelledby="adversarially-robust-spiking-neural-networks-with-sparse-connectivity"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=VhCOSdgFl2">Adversarially Robust Spiking Neural Networks with Sparse Connectivity</a></h3><p>Mathias Schmolli, Maximilian Baronig, Robert Legenstein, Ozan Ozdenizci</p><p class="fs-2">Keywords: <em>adversarial robustness, spiking neural networks, ANN-to-SNN conversion, sparsity, robust pruning</em></p><h3 id="quantum-eigengame-for-excited-state-calculation"> <a href="#quantum-eigengame-for-excited-state-calculation" class="anchor-heading" aria-labelledby="quantum-eigengame-for-excited-state-calculation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=XFjwzut6c5">Quantum EigenGame for excited state calculation</a></h3><p>David A. Quiroga, Jason Han, Anastasios Kyrillidis</p><p class="fs-2">Keywords: <em>variational quantum algorithms, PCA, EigenGame, eigensolvers</em></p><h3 id="improving-neuron-level-interpretability-with-white-box-language-models-oral"> <a href="#improving-neuron-level-interpretability-with-white-box-language-models-oral" class="anchor-heading" aria-labelledby="improving-neuron-level-interpretability-with-white-box-language-models-oral"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=XPpbo0zC4Y">Improving Neuron-level Interpretability with White-box Language Models</a> <strong><em>(Oral)</em></strong></h3><p>Hao Bai, Yi Ma</p><p class="fs-2">Keywords: <em>White-box models, deep learning architectures, neuron-level interpretation</em></p><h3 id="you-only-debias-once-towards-flexible-accuracy-fairness-trade-offs-at-inference-time-oral"> <a href="#you-only-debias-once-towards-flexible-accuracy-fairness-trade-offs-at-inference-time-oral" class="anchor-heading" aria-labelledby="you-only-debias-once-towards-flexible-accuracy-fairness-trade-offs-at-inference-time-oral"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=XYMWd1wNlf">You Only Debias Once: Towards Flexible Accuracy-Fairness Trade-offs at Inference Time</a> <strong><em>(Oral)</em></strong></h3><p>Xiaotian Han, Tianlong Chen, Kaixiong Zhou, Zhimeng Jiang, Zhangyang Wang, Xia Hu</p><p class="fs-2">Keywords: <em>fairness, weight space, neural network subspace</em></p><h3 id="grouped-sequential-optimization-strategy---the-application-of-hyperparameter-importance-assessment-in-deep-learning"> <a href="#grouped-sequential-optimization-strategy---the-application-of-hyperparameter-importance-assessment-in-deep-learning" class="anchor-heading" aria-labelledby="grouped-sequential-optimization-strategy---the-application-of-hyperparameter-importance-assessment-in-deep-learning"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=YIhDWlfQsH">Grouped Sequential Optimization Strategy - the Application of Hyperparameter Importance Assessment in Deep Learning</a></h3><p>Ruinan Wang, Ian T. Nabney, MOHAMMAD GOLBABAEE</p><p class="fs-2">Keywords: <em>Optimization, Hyperparameter Optimization, Hyperparameter Importance Assessment, Model Efficiency, Search Space Exploration, Resource Allocation</em></p><h3 id="the-computational-limits-of-state-space-models-and-mamba-via-the-lens-of-circuit-complexity-oral"> <a href="#the-computational-limits-of-state-space-models-and-mamba-via-the-lens-of-circuit-complexity-oral" class="anchor-heading" aria-labelledby="the-computational-limits-of-state-space-models-and-mamba-via-the-lens-of-circuit-complexity-oral"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=bImlLT3r62">The Computational Limits of State-Space Models and Mamba via the Lens of Circuit Complexity</a> <strong><em>(Oral)</em></strong></h3><p>Yifang Chen, Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song</p><p class="fs-2">Keywords: <em>State-Space Models, Mamba, Circuit Complexity, Computational Limits</em></p><h3 id="curse-of-attention-a-kernel-based-perspective-for-why-transformers-fail-to-generalize-on-time-series-forecasting-and-beyond"> <a href="#curse-of-attention-a-kernel-based-perspective-for-why-transformers-fail-to-generalize-on-time-series-forecasting-and-beyond" class="anchor-heading" aria-labelledby="curse-of-attention-a-kernel-based-perspective-for-why-transformers-fail-to-generalize-on-time-series-forecasting-and-beyond"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=bdOmItHgU5">Curse of Attention: A Kernel-Based Perspective for Why Transformers Fail to Generalize on Time Series Forecasting and Beyond</a></h3><p>Yekun Ke, Yingyu Liang, Zhenmei Shi, Zhao Song, Chiwun Yang</p><p class="fs-2">Keywords: <em>Time Series Forecasting, Transformer Generalization, Kernel Methods</em></p><h3 id="asymptotic-behavior-of-the-coordinate-ascent-variational-inference-in-singular-models"> <a href="#asymptotic-behavior-of-the-coordinate-ascent-variational-inference-in-singular-models" class="anchor-heading" aria-labelledby="asymptotic-behavior-of-the-coordinate-ascent-variational-inference-in-singular-models"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=e9Isd3GFDb">Asymptotic Behavior of the Coordinate Ascent Variational Inference in Singular Models</a></h3><p>Sean C Plummer, Anirban Bhattacharya, Debdeep Pati, Yun Yang</p><p class="fs-2">Keywords: <em>Coordinate Ascent Variational Inference, Singular Models, Dynmaical Systems</em></p><h3 id="theoretical-and-empirical-advances-in-forest-pruning"> <a href="#theoretical-and-empirical-advances-in-forest-pruning" class="anchor-heading" aria-labelledby="theoretical-and-empirical-advances-in-forest-pruning"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=eVAjcRE8tx">Theoretical and Empirical Advances in Forest Pruning</a></h3><p>Albert Dorador</p><p class="fs-2">Keywords: <em>Regression, Decision Trees, Ensemble Learning, Pruning, Interpretable Machine Learning</em></p><h3 id="bridging-domain-adaptation-and-graph-neural-networks-a-tensor-based-framework-for-effective-label-propagation"> <a href="#bridging-domain-adaptation-and-graph-neural-networks-a-tensor-based-framework-for-effective-label-propagation" class="anchor-heading" aria-labelledby="bridging-domain-adaptation-and-graph-neural-networks-a-tensor-based-framework-for-effective-label-propagation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=erHR9IqQBQ">Bridging Domain Adaptation and Graph Neural Networks: A Tensor-Based Framework for Effective Label Propagation</a></h3><p>Tao Wen, Elynn Chen, Yuzhou Chen, Qi Lei</p><p class="fs-2">Keywords: <em>Graph Classification, Domain Adaptation, Label Propagation</em></p><h3 id="unlock-the-theory-behind-scaling-1-bit-neural-networks"> <a href="#unlock-the-theory-behind-scaling-1-bit-neural-networks" class="anchor-heading" aria-labelledby="unlock-the-theory-behind-scaling-1-bit-neural-networks"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=fcpRnXWvWk">Unlock the Theory behind Scaling 1-bit Neural Networks</a></h3><p>Majid Daliri, Zhao Song, Chiwun Yang</p><p class="fs-2">Keywords: <em>1-bit neural network, neural tangent kernel, scaling law theory</em></p><h3 id="moxco-how-i-learned-to-stop-exploring-and-love-my-local-minima"> <a href="#moxco-how-i-learned-to-stop-exploring-and-love-my-local-minima" class="anchor-heading" aria-labelledby="moxco-how-i-learned-to-stop-exploring-and-love-my-local-minima"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=ferFzBa9bM">MoXCo: How I learned to stop exploring and love my local minima?</a></h3><p>Esha Singh, Shoham Sabach, Yu-Xiang Wang</p><p class="fs-2">Keywords: <em>optimization, deep learning, adaptive methods</em></p><h3 id="greedy-output-approximation-towards-efficient-structured-pruning-for-llms-without-retraining"> <a href="#greedy-output-approximation-towards-efficient-structured-pruning-for-llms-without-retraining" class="anchor-heading" aria-labelledby="greedy-output-approximation-towards-efficient-structured-pruning-for-llms-without-retraining"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=hp7txxx8hv">Greedy Output Approximation: Towards Efficient Structured Pruning for LLMs Without Retraining</a></h3><p>Jianwei Li, Yijun Dong, Qi Lei</p><p class="fs-2">Keywords: <em>Efficient, Structured Pruning, LLMs</em></p><h3 id="a-unified-framework-for-sparse-plus-low-rank-matrix-decomposition-for-llms-oral"> <a href="#a-unified-framework-for-sparse-plus-low-rank-matrix-decomposition-for-llms-oral" class="anchor-heading" aria-labelledby="a-unified-framework-for-sparse-plus-low-rank-matrix-decomposition-for-llms-oral"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=hyN75SAJTI">A unified framework for Sparse plus Low-Rank Matrix Decomposition for LLMs</a> <strong><em>(Oral)</em></strong></h3><p>Mehdi Makni, Kayhan Behdin, Zheng Xu, Natalia Ponomareva, Rahul Mazumder</p><p class="fs-2">Keywords: <em>model compression, sparse plus low-rank, optimization, inference acceleration, 2:4 sparsity, hardware and system co-design</em></p><h3 id="fedpews-personalized-warmup-via-subnetworks-for-enhanced-heterogeneous-federated-learning"> <a href="#fedpews-personalized-warmup-via-subnetworks-for-enhanced-heterogeneous-federated-learning" class="anchor-heading" aria-labelledby="fedpews-personalized-warmup-via-subnetworks-for-enhanced-heterogeneous-federated-learning"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=iYwiyS1YdQ">FedPeWS: Personalized Warmup via Subnetworks for Enhanced Heterogeneous Federated Learning</a></h3><p>Nurbek Tastan, Samuel Horváth, Martin Takáč, Karthik Nandakumar</p><p class="fs-2">Keywords: <em>federated learning, heterogeneous federated learning, personalized warmup, subnetworks</em></p><h3 id="concept-bottleneck-model-with-zero-performance-loss"> <a href="#concept-bottleneck-model-with-zero-performance-loss" class="anchor-heading" aria-labelledby="concept-bottleneck-model-with-zero-performance-loss"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=ii2zoKgRJV">Concept Bottleneck Model with Zero Performance Loss</a></h3><p>Zhenzhen Wang, Aleksander Popel, Jeremias Sulam</p><p class="fs-2">Keywords: <em>interpretability, explainability, concept bottleneck model, concept explanations</em></p><h3 id="meta-controlnet-enhancing-task-adaptation-via-meta-learning"> <a href="#meta-controlnet-enhancing-task-adaptation-via-meta-learning" class="anchor-heading" aria-labelledby="meta-controlnet-enhancing-task-adaptation-via-meta-learning"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=ju63pUpq0N">Meta ControlNet: Enhancing Task Adaptation via Meta Learning</a></h3><p>Junjie Yang, Jinze Zhao, Peihao Wang, Zhangyang Wang, Yingbin Liang</p><p class="fs-2">Keywords: <em>Meta Learning, Diffusion Models, Generalization</em></p><h3 id="provable-model-parallel-distributed-principal-component-analysis-with-parallel-deflation"> <a href="#provable-model-parallel-distributed-principal-component-analysis-with-parallel-deflation" class="anchor-heading" aria-labelledby="provable-model-parallel-distributed-principal-component-analysis-with-parallel-deflation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=n3SpSUzGi0">Provable Model-Parallel Distributed Principal Component Analysis with Parallel Deflation</a></h3><p>Fangshuo Liao, Wenyi Su, Anastasios Kyrillidis</p><p class="fs-2">Keywords: <em>Principal Component Analysis, Distributed Learning</em></p><h3 id="dimension-mixer-group-mixing-of-input-dimensions-for-efficient-function-approximation"> <a href="#dimension-mixer-group-mixing-of-input-dimensions-for-efficient-function-approximation" class="anchor-heading" aria-labelledby="dimension-mixer-group-mixing-of-input-dimensions-for-efficient-function-approximation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=nJ4fuCF5aX">Dimension Mixer: Group Mixing of Input Dimensions for Efficient Function Approximation</a></h3><p>Suman Sapkota, Binod Bhattarai</p><p class="fs-2">Keywords: <em>Sparse Architectures, Structured Sparsity, Butterfly Sparsity, Butterfly MLP, Butterfly Attention, Long Range Arena (LRA), Solving Pathfinder-X, Patch Only MLP-Mixer, Dimension Mixer</em></p><h3 id="dual-reasoning-a-gnn-llm-collaborative-framework-for-knowledge-graph-question-answering"> <a href="#dual-reasoning-a-gnn-llm-collaborative-framework-for-knowledge-graph-question-answering" class="anchor-heading" aria-labelledby="dual-reasoning-a-gnn-llm-collaborative-framework-for-knowledge-graph-question-answering"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=odnOkx8Qfj">Dual Reasoning: A GNN-LLM Collaborative Framework for Knowledge Graph Question Answering</a></h3><p>Guangyi Liu, Yongqi Zhang, Yong Li, Quanming Yao</p><p class="fs-2">Keywords: <em>Large Language Model, Knowledge Graph, Question Answering</em></p><h3 id="a-validation-approach-to-over-parameterized-matrix-and-image-recovery"> <a href="#a-validation-approach-to-over-parameterized-matrix-and-image-recovery" class="anchor-heading" aria-labelledby="a-validation-approach-to-over-parameterized-matrix-and-image-recovery"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=oyQnduevQw">A Validation Approach to Over-parameterized Matrix and Image Recovery</a></h3><p>Lijun Ding, Zhen Qin, Liwei Jiang, Jinxin Zhou, Zhihui Zhu</p><p class="fs-2">Keywords: <em>Matrix recovery, low-rank, validation, gradient descent, nonconvex optimization</em></p><h3 id="revisiting-the-initial-steps-in-adaptive-gradient-descent-optimization"> <a href="#revisiting-the-initial-steps-in-adaptive-gradient-descent-optimization" class="anchor-heading" aria-labelledby="revisiting-the-initial-steps-in-adaptive-gradient-descent-optimization"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=pJVxTOUCkw">Revisiting the Initial Steps in Adaptive Gradient Descent Optimization</a></h3><p>Abulikemu Abuduweili, Changliu Liu</p><p class="fs-2">Keywords: <em>Optimization, Adam, Adaptive Gradient Decent, Neural Networks</em></p><h3 id="adaptive-batch-size-schedules-for-distributed-training-of-language-models-with-data-and-model-parallelism"> <a href="#adaptive-batch-size-schedules-for-distributed-training-of-language-models-with-data-and-model-parallelism" class="anchor-heading" aria-labelledby="adaptive-batch-size-schedules-for-distributed-training-of-language-models-with-data-and-model-parallelism"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=pi2TiX7er9">Adaptive Batch Size Schedules for Distributed Training of Language Models with Data and Model Parallelism</a></h3><p>Tim Tsz-Kit Lau, Weijian Li, Chenwei Xu, Han Liu, Mladen Kolar</p><p class="fs-2">Keywords: <em>Distributed training, adaptive batch size, data parallelism, model parallelism</em></p><h3 id="heterogeneous-decision-making-in-mixed-traffic-uncertainty-aware-planning-and-bounded-rationality"> <a href="#heterogeneous-decision-making-in-mixed-traffic-uncertainty-aware-planning-and-bounded-rationality" class="anchor-heading" aria-labelledby="heterogeneous-decision-making-in-mixed-traffic-uncertainty-aware-planning-and-bounded-rationality"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=pxg38Rw63r">Heterogeneous Decision Making in Mixed Traffic: Uncertainty-aware Planning and Bounded Rationality</a></h3><p>Hang Wang, Qiaoyi Fang, Junshan Zhang</p><p class="fs-2">Keywords: <em>Mixed Traffic, Reinforcement Learning, Planning, Bounded Rationality</em></p><h3 id="do-global-and-local-perform-cooperatively-or-adversarially-in-heterogeneous-federated-learning"> <a href="#do-global-and-local-perform-cooperatively-or-adversarially-in-heterogeneous-federated-learning" class="anchor-heading" aria-labelledby="do-global-and-local-perform-cooperatively-or-adversarially-in-heterogeneous-federated-learning"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=qOzt8VNQMx">Do Global and Local Perform Cooperatively or Adversarially in Heterogeneous Federated Learning?</a></h3><p>Huiwen Wu, Shuo Zhang</p><p class="fs-2">Keywords: <em>federated learning; multilevel optimization; learning dynamics</em></p><h3 id="a-case-study-of-low-ranked-self-expressive-structures-in-neural-network-representations-oral"> <a href="#a-case-study-of-low-ranked-self-expressive-structures-in-neural-network-representations-oral" class="anchor-heading" aria-labelledby="a-case-study-of-low-ranked-self-expressive-structures-in-neural-network-representations-oral"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=vMGYwMFRKf">A Case Study of Low Ranked Self-Expressive Structures in Neural Network Representations</a> <strong><em>(Oral)</em></strong></h3><p>Uday Singh Saini, William Shiao, Yahya Sattar, Yogesh Dahiya, Samet Oymak, Evangelos E. Papalexakis</p><p class="fs-2">Keywords: <em>Subspace Clustering, Centered Kernel Alignment, Representation Similarity Measures.</em></p><h3 id="adaprox-a-novel-method-for-bilevel-optimization-under-pessimistic-framework"> <a href="#adaprox-a-novel-method-for-bilevel-optimization-under-pessimistic-framework" class="anchor-heading" aria-labelledby="adaprox-a-novel-method-for-bilevel-optimization-under-pessimistic-framework"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=wRMu5wPgQ7">AdaProx: A Novel Method for Bilevel Optimization under Pessimistic Framework</a></h3><p>Ziwei Guan, Daouda Sow, Sen Lin, Yingbin Liang</p><p class="fs-2">Keywords: <em>pessimistic bilevel optimization, convergence analysis, nonconvex, gradient-based method</em></p><h3 id="hsr-enhanced-sparse-attention-acceleration"> <a href="#hsr-enhanced-sparse-attention-acceleration" class="anchor-heading" aria-labelledby="hsr-enhanced-sparse-attention-acceleration"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=wso1gABiPZ">HSR-Enhanced Sparse Attention Acceleration</a></h3><p>Bo Chen, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song</p><p class="fs-2">Keywords: <em>Half-Space Reporting, Attention Acceleration, Sparse Attention</em></p><h3 id="learning-of-patch-based-smooth-plus-sparse-models-for-image-reconstruction"> <a href="#learning-of-patch-based-smooth-plus-sparse-models-for-image-reconstruction" class="anchor-heading" aria-labelledby="learning-of-patch-based-smooth-plus-sparse-models-for-image-reconstruction"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=xJpLu0Dicu">Learning of Patch-Based Smooth-Plus-Sparse Models for Image Reconstruction</a></h3><p>Stanislas Ducotterd, Sebastian Neumayer, Michael Unser</p><p class="fs-2">Keywords: <em>Image reconstruction, sparsity, dictionary learning, deep equilibrium</em></p><h3 id="large-scale-multiway-clustering-with-seeded-clustering"> <a href="#large-scale-multiway-clustering-with-seeded-clustering" class="anchor-heading" aria-labelledby="large-scale-multiway-clustering-with-seeded-clustering"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=xfA9mu6NQL">Large-Scale Multiway Clustering with Seeded Clustering</a></h3><p>Jiaxin Hu</p><p class="fs-2">Keywords: <em>scalable algorithm, time complexity, space complexity, large-scale data, tensor clustering, seeded clustering</em></p><h3 id="fast-john-ellipsoid-computation-with-differential-privacy-optimization-oral"> <a href="#fast-john-ellipsoid-computation-with-differential-privacy-optimization-oral" class="anchor-heading" aria-labelledby="fast-john-ellipsoid-computation-with-differential-privacy-optimization-oral"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=yfmFSc5ZPG">Fast John Ellipsoid Computation with Differential Privacy Optimization</a> <strong><em>(Oral)</em></strong></h3><p>Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song, Junwei Yu</p><p class="fs-2">Keywords: <em>Fast Optimization, Differential Privacy, John Ellipsoid Computation</em></p><h3 id="approximate-nullspace-augmented-finetuning-for-robust-vision-transformers-oral"> <a href="#approximate-nullspace-augmented-finetuning-for-robust-vision-transformers-oral" class="anchor-heading" aria-labelledby="approximate-nullspace-augmented-finetuning-for-robust-vision-transformers-oral"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://openreview.net/forum?id=zH3Zwx3dLQ">Approximate Nullspace Augmented Finetuning for Robust Vision Transformers</a> <strong><em>(Oral)</em></strong></h3><p>Haoyang Liu, Aditya Singh, Yijiang Li, Haohan Wang</p><p class="fs-2">Keywords: <em>Robustness, Vision Transformer, Invariance</em></p></main></div></div><div class="search-overlay"></div></div>
